{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "GUasYn4NRLWC",
    "tags": []
   },
   "source": [
    "# Scientific Machine Learning: PINN For Audio Processing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**ASSA 2025 Autumn school**\n",
    "\n",
    "Mirco PEZZOLI - Politecnico di Milano, Milan, Italy\n",
    "\n",
    "> Note: this notebook is based on my [Forum Acusticum 2025 summer school](https://github.com/m-pexx/fa25-summer-school) and the [EUSIPCO 2025 tutorial](https://github.com/Chutlhu/EUSIPCO25_PIML_tutorial) on PIML for audio processing\n",
    "[Credits include Doc. [Diego Di Carlo](https://diegodicarlo.com/index.html) and Prof. [Shoichi Koyama](https://www.sh01.org/)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "3OgHXggsm598",
    "tags": []
   },
   "source": [
    "## Assignment\n",
    "- Implement a **Physics-Informed Neural Network (PINN)** for inverse problem solving. In particular, for interpolating RIRs using a PI-SIREN as proposed in \"Implicit neural representation with physics-informed neural networks for the reconstruction of the early part of room impulse responses\" by Pezzoli et al. presented at Forum Acusticum 2023. Read the paper [here](https://www.researchgate.net/profile/Mirco-Pezzoli/publication/377549887_Implicit_Neural_Representation_With_Physics-Informed_Neural_Networks_For_The_Reconstruction_Of_The_Early_Part_Of_Room_Impulse_Responses/links/665995c6479366623a3382e3/Implicit-Neural-Representation-With-Physics-Informed-Neural-Networks-For-The-Reconstruction-Of-The-Early-Part-Of-Room-Impulse-Responses.pdf).\n",
    "\n",
    "- The model is based on a Physics-informed SIREN, which is a MLP with sinusoidal activations. Read about SIREN on the original paper [here](https://arxiv.org/abs/2006.09661).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "VB-SAoLWSfG1",
    "tags": []
   },
   "source": [
    "# Let's start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "hXas80wJS_6T",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# We start importing some libraries\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile as wavfile\n",
    "\n",
    "sys.path.append('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "executionInfo": {
     "elapsed": 116,
     "status": "ok",
     "timestamp": 1761925493815,
     "user": {
      "displayName": "Mirco Pezzoli",
      "userId": "07447080668207017747"
     },
     "user_tz": -60
    },
    "id": "wPlms3fxRS61",
    "outputId": "6ee63152-19a9-4c35-f027-5d2c78de6a6c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If GPU (if running in Colab: Runtime -> Change runtime type -> GPU (recommended))\n",
    "#!nvidia-smi  # Uncomment to see GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1761925503036,
     "user": {
      "displayName": "Mirco Pezzoli",
      "userId": "07447080668207017747"
     },
     "user_tz": -60
    },
    "id": "-DdOH9nFTAj_",
    "outputId": "85b91029-eee9-4197-9032-dc1541450770",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run on the available device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Current device:', device)\n",
    "\n",
    "# Set the seed number\n",
    "def reset_seeds(seed=123):\n",
    "    \"\"\"Reset all random seeds to e nsure reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "SEED =\n",
    "reset_seeds(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "AccEOyUBm59_",
    "tags": []
   },
   "source": [
    "All set with the necesarry settings. Let start! ðŸš€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "cq2LuZU8m5-F",
    "tags": []
   },
   "source": [
    "## InvPINN Model Class\n",
    "\n",
    "Before focuing on the RIR reconstrcution problem, let's setup the models that we are going to use in the training. In particular, we adapt the class `PINN_Wave1D` class for inverse problems\n",
    "\n",
    "In practice we **extend the class** to include data loss, as sampling and derivatives functions remain the same.\n",
    "\n",
    "First, import the PINN_Wave1D class from the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vX2NnNCg2E9m"
   },
   "outputs": [],
   "source": [
    "# Copy-paste the class PINN_Wave1D from previous notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYRh1Rx5BI6m"
   },
   "source": [
    "Secondly, we import the PINN_Wave1D_inverse class in order to have a suitable MLP that deals with data loss\n",
    "\n",
    "> Hint: have a look at this NN class in the notebook on the PINN introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "sM9Ip9i0m5-F",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PINN_Wave1D_inverse(PINN_Wave1D):\n",
    "    def __init__(self,\n",
    "        model_arch,\n",
    "        wave_speed=1.0, wave_mode=1, domain_length=1.0,  # <-- used for viz. purpose\n",
    "        samples_sizes = {'N_pde': 2048,},\n",
    "        loss_weights = {'pde' : 1., # <-- need to add a weight for the dataloss!\n",
    "        device='cpu',\n",
    "        ):\n",
    "        super().__init__(model_arch, wave_speed, wave_mode, domain_length, samples_sizes, loss_weights, device)\n",
    "        self.w_pde = loss_weights['pde']\n",
    "        self.w_data = # <-- need to add a loss on the data!\n",
    "\n",
    "    def train(self,\n",
    "              tz_data,  # <-- need to pass the data in the training function\n",
    "              n_iters=1500, lr=1e-3, log_every=100, plot_live=False):\n",
    "        \"\"\"Train the PINN model\"\"\"\n",
    "        self.model.train()\n",
    "        opt = # <-- set the optimizer!\n",
    "        hist = []\n",
    "\n",
    "        # Evaluation points for live plotting\n",
    "        if plot_live:\n",
    "            z_eval = torch.linspace(0, self.L, 400)[:, None]\n",
    "            t_eval = 0.35\n",
    "            tz_eval = torch.cat([torch.full_like(z_eval, t_eval), z_eval], dim=1).to(self.device)\n",
    "\n",
    "        for step in range(n_iters):\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "\n",
    "            # (1) PDE loss\n",
    "            tz_c = # <-- retrieve the collocation points (i.e., domain over which compute the PDE loss)\n",
    "            u_c =  # <-- get the estimte of from the NN\n",
    "            ut_c, uz_c, utt_c, uzz_c = # <-- get the derivates!\n",
    "            r =  # <-- implement PDE residual\n",
    "            L_pde = torch.mean(r**2)\n",
    "\n",
    "            # (4) Data / Supervised losses\n",
    "            u_d = # <-- Get the model prediction!\n",
    "            L_data = torch.mean((u_d - u_data)**2)\n",
    "\n",
    "            # (6) total loss & step\n",
    "            loss = # <-- combine the two losses weighted\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            # some loggings\n",
    "            if step % log_every == 0:\n",
    "                parts = {\n",
    "                    'pde': float(L_pde.detach().cpu()),\n",
    "                    'data': float(L_data.detach().cpu()),\n",
    "                }\n",
    "                hist.append((step, float(loss.detach().cpu()), parts))\n",
    "                print(f\"[Adam {step:04d}] total={hist[-1][1]:.3e} parts={parts}\")\n",
    "\n",
    "                if plot_live:\n",
    "                    self._plot_live_training(hist, tz_eval, z_eval, t_eval, step=step, total_steps=n_iters)\n",
    "\n",
    "        if plot_live:\n",
    "            self._plot_live_training(hist, tz_eval, z_eval, t_eval, step=step, total_steps=n_iters)\n",
    "\n",
    "        u_pred = self.model(tz_eval)\n",
    "        u_ref = self.analytical_solution(t_eval, z_eval.to(self.device))\n",
    "        mse = torch.mean((u_pred - u_ref)**2).mean()\n",
    "        print(f'Training ended. Final MSE {mse.item()}')\n",
    "\n",
    "        return hist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iF9EK0z89YI"
   },
   "source": [
    "# SIREN model\n",
    "\n",
    "We want to implement a PI-SIREN which is a MLP with sinusoidal activation and train it to estimate RIRs in a uniform linear array.\n",
    "\n",
    "SIREN has the structure of MLP defined by several layer $\\phi$ as\n",
    "\n",
    "$g(\\boldsymbol{x} ; \\boldsymbol{\\theta})=\\left(\\phi_L \\circ \\phi_{L-1} \\circ \\cdots \\circ \\phi_1\\right)(\\boldsymbol{x})$\n",
    "\n",
    "where $x$ is the input of the MLP and $\\theta$ are the learnable parameters of the model.\n",
    "\n",
    "\n",
    "Each $i$th layer is characterized by sinusoidal activation leading to\n",
    "\n",
    "$\\phi_i\\left(\\boldsymbol{x}_i\\right)=\\sin \\left(\\omega_0 \\boldsymbol{x}_i^T \\boldsymbol{\\theta}_i+\\boldsymbol{b}_i\\right)$\n",
    "\n",
    "where $\\omega_0$ is a hyperparameter that controls the freuquency of the sinusoidal function. For more details about the impact of $\\omega_0$ read the [paper](https://arxiv.org/abs/2006.09661) by Sitzman.\n",
    "\n",
    "**Why** (vs tanh/ReLU MLPs)\n",
    "- Battles **spectral bias** â†’ captures high-frequency/detail (e.g., Helmholtz high-k, sharp boundaries)\n",
    "- Stable gradients over space/time for INRs & PINNs\n",
    "- Originally proposed for image super-resolution and also PINNs\n",
    "\n",
    "**When to use**\n",
    "- Coordinate-based fields (signal/image/audio)\n",
    "- PDEs with **oscillatory** solutions, multi-scale detail.\n",
    "\n",
    "**Tips for PINNs**\n",
    "- Normalize inputs coordinates to $[-1,1]$\n",
    "- $\\omega_0$ should match the \"bandwidth\" of the signal, i.e., the higher the frequency content, the bigger the $\\omega_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZzZs7xTN2x8M"
   },
   "outputs": [],
   "source": [
    "# Implement the SIREN model\n",
    "# SIREN layer and network (great for oscillatory signals)\n",
    "class Sine(nn.Module):\n",
    "    def __init__(self, w0=30.0):\n",
    "        super().__init__()\n",
    "        self.w0 = w0\n",
    "    def forward(self, x):\n",
    "        return # <-- implement the Sinusoidal layer\n",
    "\n",
    "def siren_init(m, w0): # SIREN requires particular initialization\n",
    "    if isinstance(m, nn.Linear):\n",
    "        in_f = m.weight.shape[1]\n",
    "        bound = 1./in_f if hasattr(m, 'is_first') else math.sqrt(6/in_f)/w0\n",
    "        with torch.no_grad():\n",
    "            m.weight.uniform_(-bound, bound);\n",
    "            if m.bias is not None: m.bias.uniform_(-bound, bound)\n",
    "\n",
    "class SirenNet(nn.Module):\n",
    "    def __init__(self, in_dim=2, hidden=64, depth=4, w0 # <-- Set initial omega0\n",
    "                 , w0_hidden=1.0):\n",
    "        super().__init__()\n",
    "        layers=[]\n",
    "        for i in range(depth):\n",
    "            lin = nn.Linear(in_dim if i==0 else hidden, hidden)\n",
    "            if i==0:\n",
    "                lin.is_first=True\n",
    "                layers += [lin, # <-- first layer use w0\n",
    "            else:\n",
    "                layers += [lin, # <-- others use w0_hidden\n",
    "        layers += # <-- last layer is linear!\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.apply(lambda m: siren_init(m, w0_hidden))\n",
    "\n",
    "    def forward(self, tx): return self.net(tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "V8TJRvGzm5-J",
    "tags": []
   },
   "source": [
    "## Room Impulse Response (RIR) reconstruction\n",
    "\n",
    "Let's apply PI-SIREN for **sound field reconstruction**, in particular spatial upsampling of measurement Room Impulse Responses (RIRs).\n",
    "\n",
    "\n",
    "### How to proceed\n",
    "1. Train the PINN without removing any channel from the array and using only the data loss. This data fit will show if architecture works.\n",
    "2. Impose the random mask to remove channels from the ULA and train the network.\n",
    "3. Add the PDE loss to the training, what can you observe? You probably have to play with weighting factors $\\lambda$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "MAp295Xcm5-J",
    "tags": []
   },
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "editable": true,
    "executionInfo": {
     "elapsed": 790,
     "status": "ok",
     "timestamp": 1761923940175,
     "user": {
      "displayName": "Mirco Pezzoli",
      "userId": "07447080668207017747"
     },
     "user_tz": -60
    },
    "id": "gkh96g2Rm5-J",
    "outputId": "2c781e96-dbf2-4421-fb40-ad647df2fe6b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wavfile\n",
    "!wget https://github.com/m-pexx/fa25-summer-school/raw/refs/heads/main/data/simulated_rir2.wav\n",
    "\n",
    "fs, data = wavfile.read(\"./simulated_rir2.wav\")\n",
    "print(data.shape)\n",
    "\n",
    "# normalized\n",
    "data = # <-- peak normalize the data\n",
    "data =  # <--- Get the first 200 time samples to keep small size\n",
    "n_samples, n_mics = data.shape\n",
    "\n",
    "# let's create a random mask selecting 70% of the mics\n",
    "mask_np = np.ones(data.shape)\n",
    "N_mics_to_remove = # <-- Set the number of mics to remove\n",
    "print(N_mics_to_remove)\n",
    "idx_remove = np.sort(np.random.choice(np.arange(data.shape[1]), N_mics_to_remove, replace=False))\n",
    "idx_to_keep = np.setdiff1d(np.arange(data.shape[1]), idx_remove)\n",
    "mask_np[:,idx_remove] *= 0\n",
    "\n",
    "fig, axarr = plt.subplots(1,2, figsize=(7,3), sharey=True)\n",
    "axarr[0].imshow(data, aspect='auto', cmap=\"seismic\", vmax=1, vmin=-1)\n",
    "axarr[0].set_xlabel('Channel index')\n",
    "axarr[0].set_ylabel('Samples')\n",
    "axarr[1].imshow(mask_np * data , aspect='auto', cmap=\"seismic\", vmax=1, vmin=-1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "3mr88q1Sm5-J",
    "tags": []
   },
   "source": [
    "### Adapt the PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "VrRONn5Om5-J",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "class PINN_RIRs(PINN_Wave1D_inverse):\n",
    "    def __init__(self,\n",
    "        model_arch,\n",
    "        samples_sizes = {'N_pde': 2048,},\n",
    "        loss_weights = {'pde' : 1., 'data' : 1.,},\n",
    "        device='cpu',\n",
    "    ):\n",
    "        super().__init__(model_arch, 1, 1, 1, samples_sizes, loss_weights, device)\n",
    "        self.w_pde = loss_weights['pde']\n",
    "        self.w_data = loss_weights['data']\n",
    "        self.c = 343.                        # <--- change the speed of sound\n",
    "\n",
    "    def sample_collocation(self, Nc):\n",
    "        \"\"\"Sample collocation points in domain [0,1] x [0,L]\"\"\"\n",
    "        t = torch.rand(Nc, 1) * 2 - 1      # <--- change the input domain in [-1,1]\n",
    "        z = torch.rand(Nc, 1) * 2 - 1      # <--- change the input domain in [-1,1]\n",
    "        return torch.cat([t, z], dim=1).to(self.device)\n",
    "\n",
    "    def train(self, tz_data, u_data, tz_ref, u_ref, n_iters=1500, lr=1e-3, log_every=100, plot_live=False):\n",
    "        \"\"\"Train the PINN model\"\"\"\n",
    "        self.model.train()\n",
    "        opt = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        hist = []\n",
    "\n",
    "        # Evaluation points for live plotting\n",
    "        for step in range(n_iters):\n",
    "\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # (1) PDE loss\n",
    "            tz_c = # <-- retrieve the collocation points (i.e., domain over which compute the PDE loss)\n",
    "            u_c =  # <-- get the estimte of from the NN\n",
    "            ut_c, uz_c, utt_c, uzz_c = # <-- get the derivates!\n",
    "            r =  # <-- implement PDE residual\n",
    "            L_pde = torch.mean(r**2)\n",
    "\n",
    "            # (4) Data / Supervised losses\n",
    "            u_d = # <-- Get the model prediction!\n",
    "            L_data = torch.mean((u_d - u_data)**2)\n",
    "\n",
    "            # (6) total loss & step\n",
    "            loss = # <-- combine the two losses weighted\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            if step % log_every == 0:\n",
    "                parts = {\n",
    "                    'pde': float(L_pde.detach().cpu()),\n",
    "                    'data': float(L_data.detach().cpu()),\n",
    "                }\n",
    "                hist.append((step, float(loss.detach().cpu()), parts))\n",
    "                print(f\"[Adam {step:04d}] total={hist[-1][1]:.3e} parts={parts}\")\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    u_pred = self.model(tz_ref).cpu().numpy().reshape(*u_ref.shape)\n",
    "\n",
    "                if plot_live:\n",
    "                    self._plot_live_training(hist, u_pred, u_ref.detach().cpu().numpy(), step, n_iters)\n",
    "                    print(\"Loss: %0.6f MSE: %0.6f PDE %0.6f\" %(loss.item(), (self.w_pde*L_pde).item(), (self.w_data*L_data).item()))\n",
    "\n",
    "        if plot_live:\n",
    "            self._plot_live_training(hist, u_pred, u_ref.detach().cpu().numpy(), step, n_iters)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            u_pred = self.model(tz_ref).reshape(*u_ref.shape)\n",
    "        mse = torch.mean((u_pred - u_ref)**2)\n",
    "        print(\"Final Loss: %0.6f MSE: %0.6f PDE %0.6f\" %(loss.item(), (self.w_data*L_data).item(), (self.w_pde*L_pde).item()))\n",
    "        print(f\"Model trained. Final full field reconstruction MSE: {mse.item():0.6f}\")\n",
    "        return hist\n",
    "\n",
    "    def _plot_live_training(self, hist, u_pred, u_ref, step, total_steps, title_suffix=\"\"):\n",
    "\n",
    "        try:\n",
    "            from IPython.display import clear_output\n",
    "            clear_output(wait=True)\n",
    "        except ImportError:\n",
    "            pass  # Skip clearing output if IPython not available\n",
    "\n",
    "        steps, totals, comps = zip(*hist)\n",
    "        pde = [c['pde'] for c in comps]\n",
    "        data = [c['data'] for c in comps] if 'data' in comps[0] else None\n",
    "\n",
    "        fig, axarr = plt.subplots(1,4, figsize=(14,5))\n",
    "        axarr[0].imshow(u_ref, aspect='auto', cmap=\"seismic\", vmin=-1.1, vmax=1.1)\n",
    "        axarr[0].set_xlabel('Channel index')\n",
    "        axarr[0].set_ylabel('Samples')\n",
    "        axarr[0].set_title('Reference')\n",
    "\n",
    "        axarr[1].imshow(u_pred , aspect='auto', cmap=\"seismic\", vmin=-1.1, vmax=1.1)\n",
    "        axarr[1].set_xlabel('Channel index')\n",
    "        axarr[1].set_ylabel('Samples')\n",
    "        axarr[1].set_title('Prediction')\n",
    "        axarr[2].plot(steps, pde, label='PDE')\n",
    "        if data is not None:\n",
    "            axarr[2].plot(steps, data, label='Data')\n",
    "        axarr[2].set_xlim([0, total_steps])\n",
    "        axarr[2].set_title(\"Loss Components\")\n",
    "        axarr[2].set_xlabel(\"Steps\")\n",
    "        axarr[2].legend()\n",
    "        axarr[2].grid(True)\n",
    "\n",
    "        axarr[3].plot(steps, self.w_pde * np.array(pde), label='PDE')\n",
    "        if data is not None:\n",
    "            axarr[3].plot(steps, self.w_data * np.array(data), label='Data')\n",
    "        axarr[3].set_xlim([0, total_steps])\n",
    "        axarr[3].set_title(\"Weigthed Loss Components\")\n",
    "        axarr[3].set_xlabel(\"Steps\")\n",
    "        axarr[3].legend()\n",
    "        axarr[3].grid(True)\n",
    "\n",
    "        plt.suptitle(f'Training loop {step}/{total_steps} iters' + title_suffix)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "itcqH2Snm5-J",
    "tags": []
   },
   "source": [
    "### And train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "editable": true,
    "executionInfo": {
     "elapsed": 25471,
     "status": "ok",
     "timestamp": 1761924572288,
     "user": {
      "displayName": "Mirco Pezzoli",
      "userId": "07447080668207017747"
     },
     "user_tz": -60
    },
    "id": "OmCtate-m5-J",
    "outputId": "febec594-fa9f-4122-f6c1-782cdc537dcd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "z_coords = # <-- space samples\n",
    "t_coords = # <-- time samples\n",
    "\n",
    "tz_grid = np.stack(np.meshgrid(t_coords, z_coords, indexing='ij'), -1)\n",
    "print(tz_grid.shape, data.shape)\n",
    "\n",
    "# define points for qualitative evaluation\n",
    "tz_true = torch.tensor(tz_grid, dtype=torch.float32, device=device)\n",
    "u_true = torch.tensor(data, dtype=torch.float32, device=device)\n",
    "\n",
    "# define observed points\n",
    "tz_obs = torch.tensor(tz_grid[:,idx_to_keep].reshape(-1,2), dtype=torch.float32, device=device)\n",
    "u_obs = torch.tensor(data[:,idx_to_keep].reshape(-1,1), dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "reset_seeds(SEED)\n",
    "model_arch = # <-- Define the SIREN networks! Suggested parameters # hidden 128, 5 layers in total, initial omega 30 and hidden omega as half of w0\n",
    "model_inv = PINN_RIRs(\n",
    "    model_arch,\n",
    "    loss_weights= # <-- train withouth the PDE loss for testing\n",
    "    samples_sizes = {'N_pde': 2048},\n",
    "    device=device\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "### TRAINING WITHOUT GPU is quite slow, is better to use GPU computing\n",
    "_ = # <-- train for 600 epochs and learning rate 0.001\n",
    "print(f\"PINN training: elapsed time: {time.time()-start:.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "8za9gai3m5-J",
    "tags": []
   },
   "source": [
    "With loss PDE's weigths = 0, we overfit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "editable": true,
    "executionInfo": {
     "elapsed": 25236,
     "status": "ok",
     "timestamp": 1761924755040,
     "user": {
      "displayName": "Mirco Pezzoli",
      "userId": "07447080668207017747"
     },
     "user_tz": -60
    },
    "id": "CHsX1QcJm5-J",
    "outputId": "c9f8bfa2-a865-47ad-8197-b6e1669b8e46",
    "tags": []
   },
   "outputs": [],
   "source": [
    "z_coords = # <-- space samples\n",
    "t_coords = # <-- time samples # <-- Play with the input range e.g., [-10,10] it's equaivalent to change w0 for one dimension\n",
    "\n",
    "tz_grid = np.stack(np.meshgrid(t_coords, z_coords, indexing='ij'), -1)\n",
    "print(tz_grid.shape, data.shape)\n",
    "\n",
    "# define points for qualitative evaluation\n",
    "# We train the model on GPU, thus we need to load the data on the device memory\n",
    "tz_true = torch.tensor(tz_grid, dtype=torch.float32, device=device)\n",
    "u_true = torch.tensor(data, dtype=torch.float32, device=device)\n",
    "\n",
    "# define observed points\n",
    "tz_obs = torch.tensor(tz_grid[:,idx_to_keep].reshape(-1,2), dtype=torch.float32, device=device)\n",
    "u_obs = torch.tensor(data[:,idx_to_keep].reshape(-1,1), dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "reset_seeds(SEED)\n",
    "# <-- Play with w0, w0_hidden, number of hitten layers and depth!\n",
    "model_arch = # <-- Define the SIREN networks!\n",
    "model_inv = PINN_RIRs(\n",
    "    model_arch,\n",
    "    loss_weights= # <-- find good balance for PDE loss (suggested weight .5e-15)\n",
    "    samples_sizes = {'N_pde': 2048},\n",
    "    device=device\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "### TRAINING WITHOUT GPU is quite slow\n",
    "_ = # <-- train for 600 epochs and learning rate 0.001: try to play with the parameters\n",
    "print(f\"PINN training: elapsed time: {time.time()-start:.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "k_73e3PGm5-J",
    "tags": []
   },
   "source": [
    "ðŸ§ Notice:\n",
    "- **Lower reconstruction MSE**\n",
    "- Effective **interpolation** of missing sensor data\n",
    "- **Lower PDE** violation loss (not 0, though because it's penalized model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "rise": {
   "center": true,
   "css": [
    "rise.css"
   ],
   "height": "100%",
   "margin": 0.04,
   "maxScale": 2,
   "minScale": 1,
   "overview": true,
   "scroll": true,
   "slideNumber": true,
   "start_slideshow_at": "selected",
   "theme": "sky",
   "transition": "fade",
   "width": "100%"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
